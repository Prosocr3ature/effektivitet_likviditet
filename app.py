import streamlit as st
import pandas as pd
import sqlite3
from datetime import datetime, timedelta
import io
import matplotlib.pyplot as plt
import numpy as np
import random

from sklearn.ensemble import RandomForestRegressor
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

import openai
from openai.error import RateLimitError

# --- PAGE CONFIGURATION ---
st.set_page_config(page_title="üìà F√∂rs√§ljningslogg & Aff√§rer", layout="wide")
st.markdown("# üìà F√∂rs√§ljningslogg & Aff√§rer")

# --- DATABASE SETUP ---
conn = sqlite3.connect('forsaljning.db', check_same_thread=False)
cursor = conn.cursor()
cursor.execute('''
CREATE TABLE IF NOT EXISTS logg (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  datum TEXT UNIQUE,
  samtal INTEGER,
  tid_min INTEGER,
  tb REAL,
  tb_per_samtal REAL,
  tb_per_timme REAL,
  snitt_min_per_samtal REAL,
  lon REAL,
  kommentar TEXT,
  energi INTEGER,
  humor INTEGER
)
''')
cursor.execute('''
CREATE TABLE IF NOT EXISTS affarer (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  datum TEXT,
  affar_namn TEXT,
  skickad_tid TEXT,
  stangd_tid TEXT,
  minuter_till_stangning REAL,
  tb REAL
)
''')
cursor.execute('''
CREATE TABLE IF NOT EXISTS mal (
  datum TEXT PRIMARY KEY,
  tb_mal INTEGER,
  samtal_mal INTEGER,
  lon_mal INTEGER,
  specifikt TEXT,
  realistiskt TEXT,
  tidsbundet TEXT
)
''')
conn.commit()

# --- OPENAI SETUP ---
openai_key = st.secrets.get("OPENAI_KEY")
if openai_key:
    openai.api_key = openai_key
else:
    st.warning("Ingen OPENAI_KEY satt i secrets ‚Äî GPT-summering inaktiverad")

# --- MOTIVATION MESSAGE ---
msgs = [
    "üî• Disciplin sl√•r motivation ‚Äì varje dag!",
    "üöÄ Varje samtal √§r en ny chans till rekord.",
    "üí™ Fokusera p√• process, inte bara resultat.",
    "üèÜ Du t√§vlar mot dig sj√§lv ‚Äì sl√• g√•rdagens du.",
    "üå± Sm√• f√∂rb√§ttringar bygger stora framg√•ngar."
]
st.info(random.choice(msgs))

# --- SIDEBAR KPIs ---
df_all = pd.read_sql_query("SELECT * FROM logg", conn)
if not df_all.empty:
    calls = df_all['samtal'].sum()
    tb_total = df_all['tb'].sum()
    time_total = df_all['tid_min'].sum()
    aff_count = len(pd.read_sql_query("SELECT * FROM affarer", conn))
    conv = calls and aff_count / calls or 0
    tb_per_min = time_total and tb_total / time_total or 0
    st.sidebar.metric("Konverteringsgrad", f"{conv:.1%}")
    st.sidebar.metric("TB per minut", f"{tb_per_min:.2f} kr")

# --- ML SETUP: Recommendation & Clustering ---
df_model = df_all[['samtal','tid_min','tb']].dropna()
if len(df_model) >= 5:
    X = df_model[['samtal','tid_min']]; y = df_model['tb']
    rec_model = RandomForestRegressor(n_estimators=50, random_state=0)
    rec_model.fit(X, y)
else:
    rec_model = None

df_a = pd.read_sql_query("SELECT minuter_till_stangning,tb FROM affarer", conn)
if len(df_a) >= 5:
    scaler = StandardScaler()
    Xa = scaler.fit_transform(df_a)
    kmeans = KMeans(n_clusters=2, random_state=0)
    df_a['cluster'] = kmeans.fit_predict(Xa)
else:
    scaler = None; kmeans = None

# --- INPUT FORM ---
c1, c2, c3 = st.columns([1.5,1,1])

with c1:
    st.subheader("üóìÔ∏è Dagslogg")
    datum = st.date_input("Datum", datetime.today())
    samtal = st.number_input("Antal samtal", min_value=0)
    tid_h = st.number_input("Tid (timmar)", min_value=0)
    tid_m = st.number_input("Tid (minuter)", min_value=0)
    tid_min = tid_h*60 + tid_m
    tb = st.number_input("TB (kr)", min_value=0.0, step=100.0)
    kommentar = st.text_input("Kommentar")
    energi = st.slider("Energiniv√• (1‚Äì5)", 1,5,3)
    humor = st.slider("Hum√∂r (1‚Äì5)", 1,5,3)

    if st.button("üíæ Spara dagslogg"):
        tb_ps = tb/samtal if samtal else 0
        tb_pt = tb/(tid_min/60) if tid_min else 0
        snitt = tid_min/samtal if samtal else 0
        lon = tb*0.45
        cursor.execute('''
          INSERT OR REPLACE INTO logg
            (datum,samtal,tid_min,tb,tb_per_samtal,tb_per_timme,
             snitt_min_per_samtal,lon,kommentar,energi,humor)
          VALUES (?,?,?,?,?,?,?,?,?,?,?)
        ''', (
          datum.strftime("%Y-%m-%d"),
          samtal, tid_min, tb,
          tb_ps, tb_pt, snitt, lon,
          kommentar, energi, humor
        ))
        conn.commit()
        st.success("Dagslogg sparad!")

with c2:
    st.subheader("üéØ S√§tt SMART-m√•l")
    g_tb      = st.number_input("TB-m√•l", min_value=0, step=100)
    g_samtal  = st.number_input("Samtalsm√•l", min_value=0)
    g_lon     = st.number_input("L√∂nem√•l", min_value=0, step=100)
    spec      = st.text_input("Specifikt m√•l")
    real      = st.text_input("Realistiskt m√•l")
    tidsbundet= st.text_input("Tidsbundet (YYYY-MM-DD)")

    if st.button("üíæ Spara m√•l"):
        cursor.execute('''
          INSERT OR REPLACE INTO mal
            (datum,tb_mal,samtal_mal,lon_mal,
             specifikt,realistiskt,tidsbundet)
          VALUES (?,?,?,?,?,?,?)
        ''', (
          datum.strftime("%Y-%m-%d"),
          g_tb, g_samtal, g_lon,
          spec, real, tidsbundet
        ))
        conn.commit()
        st.success("SMART-m√•l sparade!")

with c3:
    st.subheader("üì§ L√§gg till aff√§r")
    aff_n = st.text_input("Aff√§rsnamn")
    sent  = st.time_input("Skickad tid")
    closed= st.time_input("St√§ngd tid")
    tb_a  = st.number_input("TB f√∂r aff√§ren", min_value=0.0, step=100.0)

    if st.button("üìå Spara aff√§r"):
        diff = (datetime.combine(datum, closed)
                - datetime.combine(datum, sent)).seconds/60
        cursor.execute('''
          INSERT INTO affarer
            (datum,affar_namn,skickad_tid,stangd_tid,minuter_till_stangning,tb)
          VALUES (?,?,?,?,?,?)
        ''', (
          datum.strftime("%Y-%m-%d"),
          aff_n, sent.strftime("%H:%M"),
          closed.strftime("%H:%M"),
          diff, tb_a
        ))
        conn.commit()
        st.success("Aff√§r sparad!")

st.divider()

# --- FLIKAR ---
tab1,tab2,tab3,tab4 = st.tabs([
  "üìä Dag","üìã Aff√§rer","üèÜ Analys","üéØ M√•lhistorik"
])

# üìä Dag
with tab1:
    df = pd.read_sql_query("SELECT * FROM logg ORDER BY datum DESC", conn)
    if not df.empty:
        df["datum"] = pd.to_datetime(df["datum"])
        st.dataframe(df, use_container_width=True)
        fig,ax = plt.subplots()
        df.plot(x="datum",y=["tb","lon"],ax=ax,marker="o")
        ax.grid(True)
        st.pyplot(fig,use_container_width=True)

        if rec_model:
            inc = st.slider("√ñka samtal med (%)", -50,100,0)
            calls0 = df.iloc[0]["samtal"]
            new_calls = calls0*(1+inc/100)
            pred = rec_model.predict([[new_calls, df.iloc[0]["tid_min"]]])[0]
            st.write(f"‚û°Ô∏è Om du √∂kar samtalen med {inc}% ‚Üí TB ‚âà {pred:.0f} kr")

# üìã Aff√§rer
with tab2:
    start = st.date_input("Aff√§rer fr√•n", datetime.today()-timedelta(days=30))
    end   = st.date_input("Aff√§rer till", datetime.today())
    df2 = pd.read_sql_query(
      "SELECT * FROM affarer WHERE datum BETWEEN ? AND ? ORDER BY datum",
      conn, params=(start.strftime("%Y-%m-%d"), end.strftime("%Y-%m-%d"))
    )
    st.dataframe(df2,use_container_width=True)

    if kmeans and scaler and not df2.empty:
        Xc = scaler.transform(df2[["minuter_till_stangning","tb"]])
        df2["cluster"] = kmeans.predict(Xc)
        st.subheader("Segmentering av aff√§rer")
        fig,ax = plt.subplots()
        ax.scatter(df2["minuter_till_stangning"],df2["tb"],c=df2["cluster"],cmap="viridis")
        ax.set_xlabel("Tid (min)")
        ax.set_ylabel("TB")
        st.pyplot(fig)

# üèÜ Analys
with tab3:
    df3 = pd.read_sql_query("SELECT * FROM logg", conn)
    if not df3.empty:
        df3["datum"]=pd.to_datetime(df3["datum"])
        df3["vecka"]=df3["datum"].dt.isocalendar().week
        weekly = df3.groupby("vecka")[["tb","samtal","lon"]].sum()
        st.subheader("Veckosammanst√§llning")
        st.dataframe(weekly)
        st.line_chart(weekly[["tb","lon"]])

        # GPT-4o-mini summering
        if openai_key:
            prom = (
                f"Veckorapport vecka {weekly.index[-1]}, "
                f"totalt TB {weekly['tb'].iloc[-1]:.0f} kr. "
                "Ge en kort, peppande sammanfattning p√• svenska."
            )
            try:
                resp = openai.ChatCompletion.create(
                    model="gpt-4o-mini",
                    messages=[{"role":"user","content":prom}]
                )
                st.markdown(resp.choices[0].message.content)
            except RateLimitError:
                st.warning("GPT √§r √∂verbelastad, f√∂rs√∂k senare.")
            except Exception as e:
                st.error(f"GPT-fel: {e}")

# üéØ M√•lhistorik
with tab4:
    dfg = pd.read_sql_query("SELECT * FROM mal ORDER BY datum DESC", conn)
    dfl = pd.read_sql_query("SELECT * FROM logg ORDER BY datum DESC", conn)
    if not dfg.empty and not dfl.empty:
        dfg["datum"]=pd.to_datetime(dfg["datum"])
        dfl["datum"]=pd.to_datetime(dfl["datum"])
        st.dataframe(dfg,use_container_width=True)
        day = st.selectbox("V√§lj dag", dfg["datum"].dt.strftime("%Y-%m-%d"))
        m = dfg[dfg["datum"]==pd.to_datetime(day)].iloc[0]
        l = dfl[dfl["datum"]==pd.to_datetime(day)].iloc[0]
        pct = l["tb"]/m["tb_mal"]*100 if m["tb_mal"] else 0
        st.write(f"TB‚Äêuppfyllelse: {pct:.0f}%")
        # simulering heatmap
        calls0, tb0 = l["samtal"], l["tb"]
        avg0 = tb0/calls0 if calls0 else 0
        sr = np.arange(max(1,int(calls0*0.7)),int(calls0*1.5)+1)
        tr = np.linspace(avg0*0.8,avg0*1.3,10)
        mat = np.outer(sr,tr)
        fig,ax=plt.subplots()
        c=ax.imshow(mat, origin="lower", aspect="auto",
                    extent=[tr[0],tr[-1],sr[0],sr[-1]])
        fig.colorbar(c,ax=ax,label="TB")
        ax.set_xlabel("Snitt-TB")
        ax.set_ylabel("Samtal")
        st.pyplot(fig)

# --- EXCEL EXPORT ---
buf = io.BytesIO()
pd.read_sql_query("SELECT * FROM logg", conn).to_excel(buf,index=False)
st.download_button(
  "üì• Ladda ner logg.xlsx",
  data=buf.getvalue(),
  file_name="logg.xlsx"
)
